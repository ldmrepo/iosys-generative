#!/usr/bin/env python3
"""
8B vs 2B ì„ë² ë”© ì„±ëŠ¥ ë¹„êµ (CPU ì „ìš©)
- GPU ë¶ˆí•„ìš”: ì‚¬ì „ ìƒì„±ëœ ì„ë² ë”© íŒŒì¼ ì‚¬ìš©
- Image GT, Hybrid GT ê¸°ì¤€ í‰ê°€
"""

import json
import numpy as np
from pathlib import Path
from collections import defaultdict
from datetime import datetime


POC_DIR = Path(__file__).parent.parent
RESULTS_DIR = POC_DIR / "results"
DATA_DIR = POC_DIR / "data"


def load_embeddings(file_path):
    """ì„ë² ë”© íŒŒì¼ ë¡œë“œ (ë‹¤ì–‘í•œ í¬ë§· ì§€ì›)"""
    with open(file_path) as f:
        data = json.load(f)

    # í¬ë§· ì •ê·œí™”
    if "embeddings" in data:
        embeddings = data["embeddings"]
    else:
        embeddings = data

    # ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    if "metadata" in data:
        meta = data["metadata"]
    else:
        meta = {k: v for k, v in data.items() if k != "embeddings"}

    return embeddings, meta


def load_ground_truth(gt_name):
    """Ground Truth ë¡œë“œ"""
    gt_path = DATA_DIR / f"ground_truth_{gt_name}.json"
    with open(gt_path) as f:
        return json.load(f)


def compute_similarity_matrix(embeddings):
    """ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬ ê³„ì‚°"""
    item_ids = list(embeddings.keys())
    emb_matrix = np.array([embeddings[item_id] for item_id in item_ids])

    # L2 ì •ê·œí™”
    norms = np.linalg.norm(emb_matrix, axis=1, keepdims=True)
    emb_matrix_normalized = emb_matrix / (norms + 1e-10)

    # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ í–‰ë ¬
    similarity_matrix = emb_matrix_normalized @ emb_matrix_normalized.T

    return item_ids, similarity_matrix


def get_rankings(item_ids, similarity_matrix, query_id, top_k=20):
    """ì¿¼ë¦¬ì— ëŒ€í•œ Top-K ê²°ê³¼ ë°˜í™˜"""
    if query_id not in item_ids:
        return []

    query_idx = item_ids.index(query_id)
    similarities = similarity_matrix[query_idx].copy()
    similarities[query_idx] = -np.inf  # ìê¸° ìì‹  ì œì™¸

    top_indices = np.argsort(-similarities)[:top_k]
    return [(item_ids[idx], float(similarities[idx])) for idx in top_indices]


def top_k_recall(predictions, ground_truth, k):
    """Top-K Recall ê³„ì‚°"""
    pred_ids = [p[0] for p in predictions[:k]]
    relevant_ids = set(ground_truth.keys())
    hits = len(set(pred_ids) & relevant_ids)
    return hits / len(relevant_ids) if relevant_ids else 0


def mrr(predictions, ground_truth):
    """MRR (Mean Reciprocal Rank) ê³„ì‚°"""
    for i, (pred_id, _) in enumerate(predictions):
        if pred_id in ground_truth:
            return 1.0 / (i + 1)
    return 0.0


def evaluate_embeddings(embeddings, gt_data, name):
    """ì„ë² ë”© ì„±ëŠ¥ í‰ê°€"""
    item_ids, similarity_matrix = compute_similarity_matrix(embeddings)

    metrics = {
        'top_1': [], 'top_3': [], 'top_5': [], 'top_10': [],
        'mrr': []
    }

    by_category = defaultdict(lambda: defaultdict(list))

    for gt_item in gt_data["ground_truth"]:
        query_id = gt_item["query_id"]
        category = gt_item.get("query_category", "unknown")
        relevant = {item["id"]: item.get("relevance", 1) for item in gt_item["relevant_items"]}

        if not relevant or query_id not in item_ids:
            continue

        predictions = get_rankings(item_ids, similarity_matrix, query_id, top_k=20)

        metrics['top_1'].append(top_k_recall(predictions, relevant, 1))
        metrics['top_3'].append(top_k_recall(predictions, relevant, 3))
        metrics['top_5'].append(top_k_recall(predictions, relevant, 5))
        metrics['top_10'].append(top_k_recall(predictions, relevant, 10))
        metrics['mrr'].append(mrr(predictions, relevant))

        by_category[category]['top_5'].append(top_k_recall(predictions, relevant, 5))
        by_category[category]['mrr'].append(mrr(predictions, relevant))

    result = {
        'name': name,
        'total_queries': len(metrics['top_1']),
        'metrics': {k: float(np.mean(v)) * 100 for k, v in metrics.items()},
        'by_category': {
            cat: {k: float(np.mean(v)) * 100 for k, v in cat_metrics.items()}
            for cat, cat_metrics in by_category.items()
        }
    }

    return result


def print_comparison_table(results, gt_name):
    """ë¹„êµ í…Œì´ë¸” ì¶œë ¥"""
    print(f"\n{'='*80}")
    print(f"  {gt_name} ê¸°ì¤€ ì„±ëŠ¥ ë¹„êµ")
    print(f"{'='*80}")
    print(f"{'ëª¨ë¸':<30} | {'Top-1':>8} | {'Top-3':>8} | {'Top-5':>8} | {'Top-10':>8} | {'MRR':>8}")
    print("-"*80)

    for result in results:
        m = result['metrics']
        print(f"{result['name']:<30} | {m['top_1']:>7.1f}% | {m['top_3']:>7.1f}% | {m['top_5']:>7.1f}% | {m['top_10']:>7.1f}% | {m['mrr']:>7.1f}%")

    # ìµœê³  ì„±ëŠ¥ í‘œì‹œ
    best_top5 = max(results, key=lambda x: x['metrics']['top_5'])
    print("-"*80)
    print(f"ğŸ† Top-5 ìµœê³ : {best_top5['name']} ({best_top5['metrics']['top_5']:.1f}%)")


def main():
    print("="*80)
    print("  8B vs 2B ì„ë² ë”© ì„±ëŠ¥ ë¹„êµ (CPU ì „ìš©)")
    print("="*80)

    # ì„ë² ë”© íŒŒì¼ ëª©ë¡ (ì „ì²´ ë°ì´í„°ì…‹ ìš°ì„ )
    embedding_files = {
        "2B ë©€í‹°ëª¨ë‹¬ ì „ì²´ (mean)": RESULTS_DIR / "qwen_embeddings_full_2b_multimodal.json",
        "8B VL ì „ì²´ (mean)": RESULTS_DIR / "qwen_vl_embeddings_full_8b.json",
        "2B ë©€í‹°ëª¨ë‹¬ 100ê°œ (mean)": RESULTS_DIR / "qwen_embeddings_multimodal_meanpool.json",
        "2B í…ìŠ¤íŠ¸ 100ê°œ (mean)": RESULTS_DIR / "qwen_embeddings_textonly.json",
        "8B VL 100ê°œ (mean)": RESULTS_DIR / "qwen_vl_embeddings_8b.json",
    }

    # ì„ë² ë”© ë¡œë“œ
    print("\nì„ë² ë”© ë¡œë“œ ì¤‘...")
    embeddings_dict = {}
    for name, path in embedding_files.items():
        if path.exists():
            emb, meta = load_embeddings(path)
            embeddings_dict[name] = emb
            dim = len(list(emb.values())[0])
            print(f"  âœ“ {name}: {len(emb)}ê°œ, {dim}ì°¨ì›")
        else:
            print(f"  âœ— {name}: íŒŒì¼ ì—†ìŒ")

    # Ground Truth ë¡œë“œ
    print("\nGround Truth ë¡œë“œ ì¤‘...")
    gt_types = {
        "Image GT": "image",
        "Hybrid GT": "hybrid",
    }

    gt_data_dict = {}
    for gt_name, gt_file in gt_types.items():
        try:
            gt_data_dict[gt_name] = load_ground_truth(gt_file)
            n_queries = len(gt_data_dict[gt_name]["ground_truth"])
            print(f"  âœ“ {gt_name}: {n_queries} ì¿¼ë¦¬")
        except FileNotFoundError:
            print(f"  âœ— {gt_name}: íŒŒì¼ ì—†ìŒ")

    # í‰ê°€ ì‹¤í–‰
    all_results = {}

    for gt_name, gt_data in gt_data_dict.items():
        print(f"\n{gt_name} í‰ê°€ ì¤‘...")
        results = []

        for emb_name, embeddings in embeddings_dict.items():
            result = evaluate_embeddings(embeddings, gt_data, emb_name)
            results.append(result)
            print(f"  âœ“ {emb_name}: Top-5 = {result['metrics']['top_5']:.1f}%")

        all_results[gt_name] = results
        print_comparison_table(results, gt_name)

    # ê²°ê³¼ ì €ì¥
    output = {
        "metadata": {
            "description": "8B vs 2B ì„ë² ë”© ì„±ëŠ¥ ë¹„êµ",
            "created_at": datetime.now().isoformat(),
            "note": "8B = Qwen3-Embedding-8B (í…ìŠ¤íŠ¸ ì „ìš©), 2B = Qwen3-VL-Embedding-2B"
        },
        "results": {
            gt_name: {r['name']: r for r in results}
            for gt_name, results in all_results.items()
        }
    }

    output_path = RESULTS_DIR / "8b_vs_2b_comparison.json"
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    print(f"\nê²°ê³¼ ì €ì¥: {output_path}")

    # ê²°ë¡  ì¶œë ¥
    print("\n" + "="*80)
    print("  ê²°ë¡ ")
    print("="*80)

    for gt_name, results in all_results.items():
        best = max(results, key=lambda x: x['metrics']['top_5'])
        r8b = next((r for r in results if "8B" in r['name']), None)

        print(f"\n[{gt_name}]")
        print(f"  ğŸ† ìµœê³  ì„±ëŠ¥: {best['name']} (Top-5: {best['metrics']['top_5']:.1f}%)")
        if r8b:
            diff = best['metrics']['top_5'] - r8b['metrics']['top_5']
            print(f"  ğŸ“Š 8B vs ìµœê³ : {r8b['metrics']['top_5']:.1f}% vs {best['metrics']['top_5']:.1f}% (ì°¨ì´: {diff:+.1f}%p)")

    print("\n" + "="*80)
    print("  ğŸ“ ë¹„êµ ëŒ€ìƒ:")
    print("     - 2B: Qwen3-VL-Embedding-2B (ë©€í‹°ëª¨ë‹¬, 2048 dim)")
    print("     - 8B VL: Qwen3-VL-Embedding-8B (ë©€í‹°ëª¨ë‹¬, 4096 dim)")
    print("="*80)


if __name__ == "__main__":
    main()
