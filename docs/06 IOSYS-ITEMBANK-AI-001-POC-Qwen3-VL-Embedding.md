# Qwen3-VL-Embedding POC 계획서

**문서 ID**: IOSYS-ITEMBANK-AI-001-POC-01
**버전**: v1.1.0
**작성일**: 2026-01-27
**수정일**: 2026-01-27
**상위 문서**: IOSYS-ITEMBANK-AI-001-R02 (기술 리서치 보고서)
**프로젝트**: AI 기반 차세대 문항은행 시스템

> **v1.1.0 변경사항**: 수학 단일 과목 POC로 범위 조정, GPU 단계적 접근 전략 추가

---

## 목차

1. [POC 개요](#1-poc-개요)
2. [목표 및 성공 기준](#2-목표-및-성공-기준)
3. [범위 정의](#3-범위-정의)
4. [테스트 데이터셋](#4-테스트-데이터셋)
5. [기술 환경](#5-기술-환경)
6. [실행 계획](#6-실행-계획)
7. [평가 방법론](#7-평가-방법론)
8. [산출물](#8-산출물)
9. [리스크 관리](#9-리스크-관리)
10. [일정 및 마일스톤](#10-일정-및-마일스톤)
11. [역할 및 책임](#11-역할-및-책임)
12. [부록](#12-부록)

---

## 1. POC 개요

### 1.1 배경

AI 기반 문항은행 시스템 구축 프로젝트의 Phase 1 (문항 벡터화 및 검색 인프라)에서 임베딩 모델 선정이 핵심 과제입니다. 2026년 1월 출시된 Qwen3-VL-Embedding 모델이 멀티모달 통합 임베딩을 제공하여 기존 접근법(KURE-v1 + SigLIP) 대비 파이프라인 단순화 가능성을 제시합니다.

### 1.2 목적

본 POC는 Qwen3-VL-Embedding 모델이 **한국어 교육 문항** 검색에 적합한지 검증하고, 기존 권장 모델 조합과 비교하여 **Go/No-Go 의사결정**을 위한 근거를 확보합니다.

### 1.3 핵심 질문

| # | 질문 | 검증 방법 |
|---|------|----------|
| Q1 | 한국어 교육 문항에서 검색 정확도가 충분한가? | Top-K Recall 측정 |
| Q2 | 텍스트+이미지 통합 임베딩이 효과적인가? | 멀티모달 vs 단일모달 비교 |
| Q3 | 기존 모델 조합 대비 성능이 우수한가? | A/B 테스트 |
| Q4 | 하드웨어 요구사항이 현실적인가? | VRAM, 속도 측정 |
| Q5 | 프로덕션 환경에서 안정적인가? | 스트레스 테스트 |

---

## 2. 목표 및 성공 기준

### 2.1 주요 목표

```
┌─────────────────────────────────────────────────────────────┐
│  Primary Goal                                               │
│  Qwen3-VL-Embedding의 한국어 교육 문항 검색 적합성 검증       │
└─────────────────────────────────────────────────────────────┘
                              │
          ┌───────────────────┼───────────────────┐
          ▼                   ▼                   ▼
┌─────────────────┐ ┌─────────────────┐ ┌─────────────────┐
│ 검색 품질 검증   │ │ 시스템 성능 검증 │ │ 운영 가능성 검증 │
│ • Top-K Recall  │ │ • Latency       │ │ • 안정성        │
│ • MRR           │ │ • Throughput    │ │ • 확장성        │
│ • 정성 평가     │ │ • VRAM Usage    │ │ • 유지보수성    │
└─────────────────┘ └─────────────────┘ └─────────────────┘
```

### 2.2 성공 기준 (Go/No-Go)

#### ✅ Go 조건 (모든 항목 충족 필요)

| 지표 | 기준 | 측정 방법 |
|------|------|----------|
| **Top-5 Recall** | ≥ 80% | 정답 문항이 상위 5개에 포함 |
| **Top-10 Recall** | ≥ 90% | 정답 문항이 상위 10개에 포함 |
| **MRR** | ≥ 0.65 | Mean Reciprocal Rank |
| **기존 대비 성능** | ≥ -5% | KURE+SigLIP 대비 |
| **P95 Latency** | ≤ 200ms | 단일 쿼리 응답 시간 |
| **VRAM Usage** | ≤ 8GB (FP16/4-bit) | 로컬 GPU 기준 |
| **안정성** | 100% | 1,000회 연속 호출 성공 |

#### ❌ No-Go 조건 (하나라도 해당 시)

| 조건 | 설명 |
|------|------|
| Top-5 Recall < 70% | 최소 검색 품질 미달 |
| 기존 대비 성능 < -15% | 유의미한 성능 저하 |
| 치명적 오류 발견 | 한국어 처리 오류, 크래시 등 |
| 4-bit에서도 8GB 초과 | 로컬 실행 불가, 클라우드 전환 필요 |

### 2.3 추가 평가 기준 (Go 시 참고)

| 지표 | 우수 | 양호 | 미흡 |
|------|------|------|------|
| 파이프라인 복잡도 감소 | > 50% | 30-50% | < 30% |
| 개발 기간 단축 예상 | > 2주 | 1-2주 | < 1주 |
| 멀티모달 검색 품질 향상 | > 10% | 5-10% | < 5% |

---

## 3. 범위 정의

### 3.1 In-Scope (포함)

| 범위 | 상세 |
|------|------|
| **모델** | Qwen3-VL-Embedding-2B, Qwen3-VL-Reranker-2B |
| **비교 대상** | KURE-v1, SigLIP, KURE+SigLIP 결합 |
| **데이터** | 수학 문항 100건 (Phase 1), 추후 다른 과목 추가 (Phase 2) |
| **태스크** | 자연어 검색, 유사 문항 검색 |
| **환경** | 개발 서버 (GPU 1대) + 클라우드 GPU (필요 시) |

### 3.2 Out-of-Scope (제외)

| 범위 | 사유 |
|------|------|
| 8B 모델 테스트 | POC 단계에서 2B로 충분 |
| 전체 데이터 임베딩 | Go 결정 후 진행 |
| 프로덕션 배포 | POC 범위 초과 |
| Fine-tuning | 기본 성능 검증 우선 |
| 비디오 입력 | 문항에 비디오 없음 |

### 3.3 가정 및 제약

**가정**:
- 수학 문항 100건이 해당 과목의 특성을 대표함
- 수학 POC 결과가 다른 과목에도 일반화 가능
- 테스트 기간 중 모델 업데이트 없음

**제약**:
- POC 기간: 최대 2주
- 인력: 개발자 1명 + 콘텐츠 담당자 1명
- GPU: RTX 2070 Super 8GB (로컬), 클라우드 GPU (필요 시)
- 예산: 클라우드 GPU 비용 최대 $20 허용

### 3.4 GPU 단계적 접근 전략

```
┌─────────────────────────────────────────────────────────────┐
│  Stage 1: 로컬 GPU (RTX 2070 8GB)                            │
│  ┌─────────────────────────────────────────────────────────┐│
│  │ • FP16 (Half Precision) 사용                             ││
│  │ • 4-bit 양자화 (BitsAndBytes) 적용                       ││
│  │ • 배치 크기: 1-2                                         ││
│  │ • 이미지 해상도 제한 (max_pixels 축소)                    ││
│  └─────────────────────────────────────────────────────────┘│
│                         │                                    │
│                         ▼ 메모리 부족 시                      │
│  ┌─────────────────────────────────────────────────────────┐│
│  │  Stage 2: 클라우드 GPU                                   ││
│  │  • RunPod RTX 3090 24GB (~$0.44/hr)                     ││
│  │  • Vast.ai RTX 3090 24GB (~$0.30/hr)                    ││
│  │  • 예상 비용: $5-15 (10-20시간)                          ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────┘
```

---

## 4. 테스트 데이터셋

### 4.1 데이터셋 구성 (Phase 1: 수학)

```
┌─────────────────────────────────────────────────────────────┐
│  POC Phase 1 테스트 데이터셋: 수학 100건                       │
├─────────────────────────────────────────────────────────────┤
│  소스: data/processed/items_part*.json (10,952건 중 샘플링)   │
│                                                             │
│  ┌───────────────────────────────────────────────────────┐ │
│  │                      수학 (2학년)                       │ │
│  │                       100건                            │ │
│  │                                                        │ │
│  │   ┌──────────┐  ┌──────────┐  ┌──────────┐            │ │
│  │   │ 이미지형 │  │ 텍스트형 │  │ LaTeX형  │            │ │
│  │   │   35건   │  │   35건   │  │   30건   │            │ │
│  │   └──────────┘  └──────────┘  └──────────┘            │ │
│  └───────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────┐
│  POC Phase 2 (추후): 다른 과목 추가                           │
├─────────────────────────────────────────────────────────────┤
│                                                             │
│  ┌─────────┐ ┌─────────┐ ┌─────────┐ ┌─────────┐           │
│  │  과학   │ │  국어   │ │  사회   │ │  영어   │           │
│  │  25건   │ │  25건   │ │  25건   │ │  25건   │           │
│  │         │ │         │ │         │ │         │ │         ││
│  │ 이미지: │ │ 이미지: │ │ 이미지: │ │ 이미지: │ │ 이미지: ││
│  │  15건   │ │  15건   │ │   5건   │ │  10건   │ │   5건   ││
│  │         │ │         │ │         │ │         │ │         ││
│  │ 텍스트: │ │ 텍스트: │ │ 텍스트: │ │ 텍스트: │ │ 텍스트: ││
│  │   5건   │ │   5건   │ │  15건   │ │  10건   │ │  15건   ││
│  └─────────┘ └─────────┘ └─────────┘ └─────────┘ └─────────┘│
│                                                             │
│  총 이미지 포함: 50건 | 텍스트 전용: 50건                     │
└─────────────────────────────────────────────────────────────┘
```

### 4.2 데이터 선정 기준

| 기준 | 설명 |
|------|------|
| **대표성** | 각 과목별 주요 문항 유형 포함 |
| **다양성** | 난이도, 문항 유형, 이미지 유형 다양화 |
| **품질** | 메타데이터 완성도 높은 문항 |
| **이미지 유형** | 그래프, 도형, 사진, 다이어그램 등 |

### 4.3 과목별 상세

#### 4.3.1 수학 (20건)

| 유형 | 건수 | 이미지 | 예시 |
|------|------|--------|------|
| 함수 그래프 | 5 | ✅ | 이차함수 그래프 해석 |
| 도형 문제 | 5 | ✅ | 삼각형 넓이, 원의 성질 |
| 수식 계산 | 5 | ✅ | 방정식 풀이 (수식 이미지) |
| 서술형 | 5 | ❌ | 증명, 풀이 과정 |

#### 4.3.2 과학 (20건)

| 유형 | 건수 | 이미지 | 예시 |
|------|------|--------|------|
| 실험 장치 | 5 | ✅ | 화학 실험 기구 |
| 다이어그램 | 5 | ✅ | 세포 구조, 회로도 |
| 그래프 해석 | 5 | ✅ | 실험 결과 그래프 |
| 개념 설명 | 5 | ❌ | 물리 법칙, 화학 반응 |

#### 4.3.3 국어 (20건)

| 유형 | 건수 | 이미지 | 예시 |
|------|------|--------|------|
| 긴 지문 | 10 | ❌ | 문학 작품, 비문학 지문 |
| 문법 | 5 | ❌ | 품사, 문장 구조 |
| 삽화 포함 | 5 | ✅ | 시각 자료 해석 |

#### 4.3.4 사회 (20건)

| 유형 | 건수 | 이미지 | 예시 |
|------|------|--------|------|
| 지도 | 5 | ✅ | 지리, 역사 지도 |
| 도표/그래프 | 5 | ✅ | 통계 자료 해석 |
| 개념 설명 | 10 | ❌ | 역사 사건, 사회 현상 |

#### 4.3.5 영어 (20건)

| 유형 | 건수 | 이미지 | 예시 |
|------|------|--------|------|
| 독해 지문 | 10 | ❌ | 장문 독해 |
| 문법 | 5 | ❌ | 영문법 문제 |
| 삽화 포함 | 5 | ✅ | 상황 묘사 이미지 |

### 4.4 Ground Truth 구성

각 문항에 대해 **유사 문항 3-5개**를 Ground Truth로 지정합니다.

```json
{
  "query_id": "MATH_001",
  "query_text": "이차함수 y = x² - 4x + 3의 그래프를 그리시오.",
  "query_image": "math_001.png",
  "relevant_items": [
    {"id": "MATH_042", "relevance": 3},  // 매우 유사
    {"id": "MATH_015", "relevance": 2},  // 유사
    {"id": "MATH_078", "relevance": 2},  // 유사
    {"id": "MATH_023", "relevance": 1}   // 관련 있음
  ]
}
```

**Relevance Score**:
- 3: 매우 유사 (거의 동일한 유형)
- 2: 유사 (같은 개념, 다른 표현)
- 1: 관련 있음 (같은 단원/주제)

---

## 5. 기술 환경

### 5.1 하드웨어

#### 로컬 개발 서버 (Stage 1)

| 구성 요소 | 사양 | 비고 |
|----------|------|------|
| **GPU** | NVIDIA RTX 2070 Super **8GB** | FP16/4-bit 필수 |
| **CPU** | Intel i7-11700KF | 8코어 16스레드 |
| **RAM** | 64GB DDR4 | |
| **Storage** | /mnt/sda 125GB 여유 | 모델 저장용 |

#### 클라우드 GPU (Stage 2, 필요 시)

| 서비스 | GPU | VRAM | 시간당 비용 |
|--------|-----|------|-------------|
| RunPod | RTX 3090 | 24GB | ~$0.44 |
| Vast.ai | RTX 3090 | 24GB | ~$0.30 |
| Lambda Labs | A10 | 24GB | ~$0.75 |

### 5.2 소프트웨어

| 구성 요소 | 버전 | 용도 |
|----------|------|------|
| **OS** | Ubuntu 22.04 LTS | |
| **Python** | 3.11 | |
| **PyTorch** | 2.2.0 | |
| **CUDA** | 12.1 | |
| **vLLM** | 0.11.0+ | 모델 서빙 |
| **Transformers** | 4.45.0+ | |
| **pgvector** | 0.7.0 | 벡터 DB |
| **PostgreSQL** | 16 | |

### 5.3 모델 구성

| 모델 | 용도 | 다운로드 |
|------|------|----------|
| Qwen3-VL-Embedding-2B | 멀티모달 임베딩 | HuggingFace |
| Qwen3-VL-Reranker-2B | 재순위화 | HuggingFace |
| KURE-v1 | 텍스트 임베딩 (비교) | HuggingFace |
| SigLIP-base | 이미지 임베딩 (비교) | HuggingFace |

### 5.4 환경 구성 스크립트

```bash
#!/bin/bash
# poc_setup.sh

# 프로젝트 디렉토리
PROJECT_DIR="/mnt/sda/worker/dev_ldm/iosys-generative"
POC_DIR="$PROJECT_DIR/poc"

mkdir -p $POC_DIR
cd $POC_DIR

# 1. 가상환경 생성
python -m venv poc_env
source poc_env/bin/activate

# 2. 의존성 설치
pip install torch==2.2.0 --index-url https://download.pytorch.org/whl/cu121
pip install transformers>=4.45.0
pip install accelerate                    # 메모리 최적화
pip install bitsandbytes                  # 4-bit 양자화
pip install sentence-transformers
pip install pgvector psycopg2-binary
pip install pandas numpy scikit-learn
pip install pillow

# 3. 모델 다운로드 (로컬 저장)
MODEL_DIR="$POC_DIR/models"
mkdir -p $MODEL_DIR

huggingface-cli download Qwen/Qwen3-VL-Embedding-2B --local-dir $MODEL_DIR/qwen3-vl-embedding-2b
huggingface-cli download Qwen/Qwen3-VL-Reranker-2B --local-dir $MODEL_DIR/qwen3-vl-reranker-2b
huggingface-cli download nlpai-lab/KURE-v1 --local-dir $MODEL_DIR/kure-v1
huggingface-cli download google/siglip-base-patch16-256-i18n --local-dir $MODEL_DIR/siglip-base

# 4. 데이터베이스 설정
sudo -u postgres psql -c "CREATE DATABASE poc_itembank;"
sudo -u postgres psql -d poc_itembank -c "CREATE EXTENSION vector;"

echo "POC 환경 구성 완료"
```

### 5.5 메모리 최적화 설정 (8GB GPU용)

```python
# config/model_config.py
import torch
from transformers import BitsAndBytesConfig

# Stage 1: FP16 설정
FP16_CONFIG = {
    "torch_dtype": torch.float16,
    "device_map": "auto",
    "low_cpu_mem_usage": True,
}

# Stage 1-B: 4-bit 양자화 설정 (메모리 부족 시)
BNB_4BIT_CONFIG = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.float16,
    bnb_4bit_use_double_quant=True,
)

# 이미지 처리 제한
IMAGE_CONFIG = {
    "max_pixels": 512 * 512,  # 기본 1024*1024에서 축소
    "min_pixels": 64 * 64,
}

# 배치 크기
BATCH_SIZE = 1  # 8GB GPU용, 메모리 여유 시 2-4로 증가
```

---

## 6. 실행 계획

### 6.1 전체 워크플로우

```
┌─────────────────────────────────────────────────────────────┐
│  Phase 1: 환경 구축 (Day 1-2)                                │
│  ┌─────────────────────────────────────────────────────────┐│
│  │ • 개발 환경 설정                                         ││
│  │ • 모델 다운로드 및 검증                                   ││
│  │ • 테스트 데이터 준비                                      ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────┬───────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 2: 임베딩 생성 (Day 3-4)                              │
│  ┌─────────────────────────────────────────────────────────┐│
│  │ • Qwen3-VL-Embedding 임베딩 생성                         ││
│  │ • KURE-v1 임베딩 생성                                    ││
│  │ • SigLIP 임베딩 생성                                     ││
│  │ • KURE+SigLIP 결합 임베딩 생성                           ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────┬───────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 3: 검색 테스트 (Day 5-7)                              │
│  ┌─────────────────────────────────────────────────────────┐│
│  │ • 검색 정확도 평가 (Top-K Recall, MRR)                   ││
│  │ • 모델 간 비교 분석                                      ││
│  │ • Reranker 효과 검증                                     ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────┬───────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 4: 성능 테스트 (Day 8-9)                              │
│  ┌─────────────────────────────────────────────────────────┐│
│  │ • Latency 측정                                          ││
│  │ • Throughput 측정                                       ││
│  │ • VRAM 사용량 측정                                       ││
│  │ • 안정성 테스트 (1,000회 연속)                            ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────┬───────────────────────────────────┘
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Phase 5: 분석 및 보고 (Day 10)                              │
│  ┌─────────────────────────────────────────────────────────┐│
│  │ • 결과 분석 및 시각화                                    ││
│  │ • Go/No-Go 판단                                         ││
│  │ • 최종 보고서 작성                                       ││
│  └─────────────────────────────────────────────────────────┘│
└─────────────────────────────────────────────────────────────┘
```

### 6.2 Phase별 상세 태스크

#### Phase 1: 환경 구축 (Day 1-2)

| ID | 태스크 | 담당 | 예상 시간 | 산출물 |
|----|--------|------|----------|--------|
| 1.1 | 개발 서버 접근 확인 | 개발자 | 0.5h | - |
| 1.2 | Python 환경 구성 | 개발자 | 1h | venv |
| 1.3 | 모델 다운로드 | 개발자 | 2h | 모델 파일 |
| 1.4 | 모델 로드 테스트 | 개발자 | 2h | 테스트 로그 |
| 1.5 | PostgreSQL + pgvector 설정 | 개발자 | 1h | DB |
| 1.6 | 테스트 데이터 100건 추출 | 콘텐츠 | 4h | JSON 파일 |
| 1.7 | Ground Truth 라벨링 | 콘텐츠 | 4h | 라벨 파일 |

#### Phase 2: 임베딩 생성 (Day 3-4)

| ID | 태스크 | 담당 | 예상 시간 | 산출물 |
|----|--------|------|----------|--------|
| 2.1 | Qwen3-VL 임베딩 스크립트 작성 | 개발자 | 2h | Python 스크립트 |
| 2.2 | Qwen3-VL 임베딩 생성 | 개발자 | 2h | 임베딩 벡터 |
| 2.3 | KURE-v1 임베딩 생성 | 개발자 | 1h | 임베딩 벡터 |
| 2.4 | SigLIP 임베딩 생성 | 개발자 | 1h | 임베딩 벡터 |
| 2.5 | KURE+SigLIP 결합 스크립트 | 개발자 | 2h | Python 스크립트 |
| 2.6 | 결합 임베딩 생성 | 개발자 | 1h | 임베딩 벡터 |
| 2.7 | pgvector에 임베딩 저장 | 개발자 | 2h | DB 테이블 |

#### Phase 3: 검색 테스트 (Day 5-7)

| ID | 태스크 | 담당 | 예상 시간 | 산출물 |
|----|--------|------|----------|--------|
| 3.1 | 검색 평가 스크립트 작성 | 개발자 | 3h | Python 스크립트 |
| 3.2 | Qwen3-VL 검색 테스트 | 개발자 | 2h | 결과 CSV |
| 3.3 | KURE-v1 검색 테스트 | 개발자 | 1h | 결과 CSV |
| 3.4 | KURE+SigLIP 검색 테스트 | 개발자 | 1h | 결과 CSV |
| 3.5 | Reranker 적용 테스트 | 개발자 | 2h | 결과 CSV |
| 3.6 | 과목별 분석 | 개발자 | 2h | 분석 결과 |
| 3.7 | 모달리티별 분석 | 개발자 | 2h | 분석 결과 |
| 3.8 | 오류 케이스 분석 | 콘텐츠 | 3h | 오류 목록 |

#### Phase 4: 성능 테스트 (Day 8-9)

| ID | 태스크 | 담당 | 예상 시간 | 산출물 |
|----|--------|------|----------|--------|
| 4.1 | Latency 측정 스크립트 작성 | 개발자 | 1h | Python 스크립트 |
| 4.2 | 단일 쿼리 Latency 측정 | 개발자 | 2h | 결과 |
| 4.3 | 배치 처리 Throughput 측정 | 개발자 | 2h | 결과 |
| 4.4 | VRAM 모니터링 | 개발자 | 1h | 결과 |
| 4.5 | 안정성 테스트 (1,000회) | 개발자 | 3h | 로그 |
| 4.6 | 메모리 누수 확인 | 개발자 | 1h | 결과 |

#### Phase 5: 분석 및 보고 (Day 10)

| ID | 태스크 | 담당 | 예상 시간 | 산출물 |
|----|--------|------|----------|--------|
| 5.1 | 결과 집계 및 시각화 | 개발자 | 2h | 차트 |
| 5.2 | Go/No-Go 판단 | TF 전체 | 1h | 결정 |
| 5.3 | 최종 보고서 작성 | 개발자 | 3h | 보고서 |
| 5.4 | 리뷰 및 승인 | TF 전체 | 1h | 승인 |

---

## 7. 평가 방법론

### 7.1 검색 정확도 평가

#### 7.1.1 Top-K Recall

```python
def top_k_recall(predictions, ground_truth, k):
    """
    predictions: 검색 결과 상위 K개 문항 ID 리스트
    ground_truth: 정답 문항 ID 리스트
    """
    hits = len(set(predictions[:k]) & set(ground_truth))
    return hits / len(ground_truth) if ground_truth else 0
```

**측정 K값**: 1, 3, 5, 10, 20

#### 7.1.2 Mean Reciprocal Rank (MRR)

```python
def mrr(predictions, ground_truth):
    """
    첫 번째 정답의 역순위 평균
    """
    for i, pred in enumerate(predictions):
        if pred in ground_truth:
            return 1.0 / (i + 1)
    return 0.0
```

#### 7.1.3 NDCG (Normalized Discounted Cumulative Gain)

```python
def ndcg_at_k(predictions, relevance_scores, k):
    """
    순위 기반 관련성 점수
    """
    dcg = sum(relevance_scores.get(pred, 0) / np.log2(i + 2) 
              for i, pred in enumerate(predictions[:k]))
    ideal_dcg = sum(sorted(relevance_scores.values(), reverse=True)[:k][i] / np.log2(i + 2)
                    for i in range(min(k, len(relevance_scores))))
    return dcg / ideal_dcg if ideal_dcg > 0 else 0
```

### 7.2 성능 평가

#### 7.2.1 Latency 측정

```python
import time

def measure_latency(model, queries, n_runs=100):
    latencies = []
    for query in queries[:n_runs]:
        start = time.perf_counter()
        _ = model.encode(query)
        latencies.append((time.perf_counter() - start) * 1000)  # ms
    
    return {
        "mean": np.mean(latencies),
        "p50": np.percentile(latencies, 50),
        "p95": np.percentile(latencies, 95),
        "p99": np.percentile(latencies, 99)
    }
```

#### 7.2.2 Throughput 측정

```python
def measure_throughput(model, data, batch_size=32):
    start = time.perf_counter()
    for i in range(0, len(data), batch_size):
        batch = data[i:i+batch_size]
        _ = model.encode(batch)
    elapsed = time.perf_counter() - start
    
    return len(data) / elapsed  # items/sec
```

#### 7.2.3 VRAM 모니터링

```python
import torch

def get_vram_usage():
    if torch.cuda.is_available():
        return {
            "allocated": torch.cuda.memory_allocated() / 1e9,  # GB
            "reserved": torch.cuda.memory_reserved() / 1e9,    # GB
            "max_allocated": torch.cuda.max_memory_allocated() / 1e9
        }
    return None
```

### 7.3 비교 분석 프레임워크

```
┌─────────────────────────────────────────────────────────────┐
│  비교 대상                                                   │
├─────────────────────────────────────────────────────────────┤
│  A: Qwen3-VL-Embedding (멀티모달 통합)                       │
│  B: KURE-v1 (텍스트 전용)                                    │
│  C: SigLIP (이미지 전용)                                     │
│  D: KURE + SigLIP (결합)                                    │
│  E: Qwen3-VL + Reranker (2단계)                             │
└─────────────────────────────────────────────────────────────┘
                              │
                              ▼
┌─────────────────────────────────────────────────────────────┐
│  비교 시나리오                                               │
├─────────────────────────────────────────────────────────────┤
│  S1: 텍스트 쿼리 → 텍스트 문항       (A vs B vs D)           │
│  S2: 텍스트 쿼리 → 이미지 포함 문항   (A vs D)               │
│  S3: 이미지 쿼리 → 유사 이미지 문항   (A vs C vs D)          │
│  S4: 복합 쿼리 → 복합 문항           (A vs D)               │
│  S5: Reranker 효과                  (A vs E)               │
└─────────────────────────────────────────────────────────────┘
```

---

## 8. 산출물

### 8.1 산출물 목록

| ID | 산출물 | 형식 | 담당 | 제출일 |
|----|--------|------|------|--------|
| D1 | POC 환경 구성 가이드 | Markdown | 개발자 | Day 2 |
| D2 | 테스트 데이터셋 | JSON | 콘텐츠 | Day 2 |
| D3 | Ground Truth 라벨 | JSON | 콘텐츠 | Day 2 |
| D4 | 임베딩 생성 스크립트 | Python | 개발자 | Day 4 |
| D5 | 검색 평가 스크립트 | Python | 개발자 | Day 7 |
| D6 | 성능 측정 스크립트 | Python | 개발자 | Day 9 |
| D7 | 검색 정확도 결과 | CSV/Excel | 개발자 | Day 7 |
| D8 | 성능 측정 결과 | CSV/Excel | 개발자 | Day 9 |
| D9 | 오류 케이스 분석 | Excel | 콘텐츠 | Day 9 |
| D10 | **POC 최종 보고서** | Markdown/PDF | 개발자 | Day 10 |

### 8.2 최종 보고서 구성

```markdown
# Qwen3-VL-Embedding POC 최종 보고서

## 1. Executive Summary
   - Go/No-Go 결론
   - 핵심 수치
   - 주요 발견사항

## 2. 테스트 환경
   - 하드웨어/소프트웨어
   - 데이터셋 개요

## 3. 검색 정확도 결과
   - 전체 결과
   - 과목별 결과
   - 모달리티별 결과
   - 모델 간 비교

## 4. 시스템 성능 결과
   - Latency
   - Throughput
   - VRAM Usage
   - 안정성

## 5. 상세 분석
   - 강점 분석
   - 약점 분석
   - 오류 케이스

## 6. 권장사항
   - Go 시 다음 단계
   - No-Go 시 대안

## 7. 부록
   - 원시 데이터
   - 스크립트 목록
```

---

## 9. 리스크 관리

### 9.1 리스크 식별

| ID | 리스크 | 영향 | 확률 | 대응 전략 |
|----|--------|------|------|----------|
| R1 | 모델 다운로드 실패 | 높음 | 낮음 | 미러 사이트 활용, 수동 다운로드 |
| R2 | **GPU 메모리 부족 (8GB)** | 높음 | **높음** | FP16 → 4-bit → 클라우드 GPU |
| R3 | 테스트 데이터 품질 이슈 | 중간 | 중간 | 데이터 검수 단계 추가 |
| R4 | 모델 버그 발견 | 높음 | 낮음 | 이슈 리포트, 대안 모델 검토 |
| R5 | 일정 지연 | 중간 | 중간 | 버퍼 일정 확보 (2일) |
| R6 | 담당자 부재 | 중간 | 낮음 | 크로스 트레이닝, 문서화 |
| R7 | 클라우드 GPU 비용 초과 | 낮음 | 낮음 | 사용 시간 모니터링, 예산 한도 설정 |

### 9.2 리스크 대응 계획

#### R2: GPU 메모리 부족 대응 (단계적 접근)

```
┌─────────────────────────────────────────────────────────────┐
│  Step 1: FP16 시도                                           │
│  예상 VRAM: ~4-5GB                                           │
└─────────────────────────┬───────────────────────────────────┘
                          │ 실패 시
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 2: 4-bit 양자화                                        │
│  예상 VRAM: ~2-3GB                                           │
└─────────────────────────┬───────────────────────────────────┘
                          │ 실패 시
                          ▼
┌─────────────────────────────────────────────────────────────┐
│  Step 3: 클라우드 GPU 전환                                    │
│  RunPod/Vast.ai RTX 3090 24GB                               │
│  예상 비용: $5-15                                            │
└─────────────────────────────────────────────────────────────┘
```

```python
# Step 1: FP16 설정
model = AutoModel.from_pretrained(
    "Qwen/Qwen3-VL-Embedding-2B",
    torch_dtype=torch.float16,
    device_map="auto",
    low_cpu_mem_usage=True
)

# Step 2: 4-bit 양자화 (Step 1 실패 시)
from transformers import BitsAndBytesConfig
bnb_config = BitsAndBytesConfig(load_in_4bit=True)
model = AutoModel.from_pretrained(
    "Qwen/Qwen3-VL-Embedding-2B",
    quantization_config=bnb_config,
    device_map="auto"
)

# 공통: 이미지 해상도 제한, 배치 크기 1
BATCH_SIZE = 1
MAX_PIXELS = 512 * 512
```

#### R4: 모델 버그 발견 시

1. GitHub 이슈 확인
2. 임시 우회 방법 모색
3. No-Go 판단 또는 대기

---

## 10. 일정 및 마일스톤

### 10.1 전체 일정

```
Week 1                              Week 2
Day 1  2  3  4  5  6  7  8  9  10  11 12
├──┬──┬──┬──┬──┬──┬──┬──┬──┬──┼──┬──┤
│  환경 │ 임베딩 │  검색 테스트  │성능│분석│버퍼│
│  구축 │  생성  │              │테스트│   │   │
└──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┴──┘
   M1    M2         M3          M4  M5
```

### 10.2 마일스톤

| ID | 마일스톤 | 완료일 | 완료 기준 |
|----|----------|--------|----------|
| M1 | 환경 구축 완료 | Day 2 | 모델 로드 성공, 데이터 준비 완료 |
| M2 | 임베딩 생성 완료 | Day 4 | 4개 모델 임베딩 DB 저장 완료 |
| M3 | 검색 테스트 완료 | Day 7 | 정확도 지표 측정 완료 |
| M4 | 성능 테스트 완료 | Day 9 | 성능 지표 측정 완료 |
| M5 | POC 완료 | Day 10 | 최종 보고서 승인 |

### 10.3 체크포인트 회의

| 일자 | 참석자 | 안건 |
|------|--------|------|
| Day 2 | TF 전체 | 환경 구축 완료 확인, 데이터 검토 |
| Day 5 | TF 전체 | 중간 점검, 초기 결과 공유 |
| Day 10 | TF 전체 | 최종 결과 리뷰, Go/No-Go 결정 |

---

## 11. 역할 및 책임

### 11.1 RACI 매트릭스

| 태스크 | 개발자 | 콘텐츠 담당자 | TF 리더 |
|--------|--------|--------------|---------|
| 환경 구축 | R/A | I | I |
| 테스트 데이터 준비 | I | R/A | C |
| Ground Truth 라벨링 | C | R/A | C |
| 임베딩 생성 | R/A | I | I |
| 검색 테스트 | R/A | C | I |
| 오류 케이스 분석 | C | R/A | C |
| 성능 테스트 | R/A | I | I |
| 최종 보고서 | R/A | C | A |
| Go/No-Go 결정 | C | C | R/A |

**범례**: R=Responsible, A=Accountable, C=Consulted, I=Informed

### 11.2 연락처

| 역할 | 담당자 | 연락처 |
|------|--------|--------|
| POC 총괄 | [TF 리더] | - |
| 개발 담당 | [개발자] | - |
| 콘텐츠 담당 | [콘텐츠 담당자] | - |

---

## 12. 부록

### 12.1 데이터 스키마

#### 문항 데이터 (items.json)

```json
{
  "items": [
    {
      "id": "MATH_001",
      "subject": "수학",
      "grade": "고1",
      "unit": "이차함수",
      "item_type": "객관식",
      "difficulty": "중",
      "text": "이차함수 y = x² - 4x + 3의 그래프를...",
      "image_path": "images/math_001.png",
      "has_image": true,
      "metadata": {
        "curriculum_code": "10수학01-02",
        "cognitive_level": "적용"
      }
    }
  ]
}
```

#### Ground Truth (ground_truth.json)

```json
{
  "queries": [
    {
      "query_id": "Q001",
      "source_item_id": "MATH_001",
      "query_type": "similar_item",
      "relevant_items": [
        {"id": "MATH_042", "relevance": 3},
        {"id": "MATH_015", "relevance": 2}
      ]
    }
  ]
}
```

### 12.2 평가 결과 템플릿

#### 검색 정확도 결과 (search_results.csv)

| query_id | model | top_1 | top_3 | top_5 | top_10 | mrr | ndcg_10 |
|----------|-------|-------|-------|-------|--------|-----|---------|
| Q001 | qwen3-vl | 1 | 1 | 1 | 1 | 1.0 | 0.95 |
| Q001 | kure-v1 | 0 | 1 | 1 | 1 | 0.33 | 0.78 |

#### 성능 측정 결과 (performance_results.csv)

| model | latency_mean | latency_p95 | throughput | vram_gb |
|-------|--------------|-------------|------------|---------|
| qwen3-vl-2b | 45.2 | 78.5 | 22.1 | 6.8 |
| kure-v1 | 12.3 | 25.1 | 81.5 | 2.1 |

### 12.3 참고 명령어

```bash
# 모델 다운로드
huggingface-cli download Qwen/Qwen3-VL-Embedding-2B

# GPU 메모리 모니터링
watch -n 1 nvidia-smi

# vLLM 서버 실행
vllm serve Qwen/Qwen3-VL-Embedding-2B --task embed --port 8000

# PostgreSQL 벡터 검색
psql -d poc_itembank -c "SELECT id, 1 - (embedding <=> query_vec) AS similarity FROM items ORDER BY similarity DESC LIMIT 10;"
```

---

## 문서 이력

| 버전 | 일자 | 변경 내용 | 작성자 |
|------|------|----------|--------|
| v1.0.0 | 2026-01-27 | 최초 작성 | AI TF |
| v1.1.0 | 2026-01-27 | 수학 단일 과목 POC로 범위 조정, GPU 단계적 접근 전략 추가 (RTX 2070 8GB → 클라우드) | AI TF |

---

**승인**

| 역할 | 이름 | 서명 | 일자 |
|------|------|------|------|
| TF 리더 | | | |
| 개발 담당 | | | |
| 콘텐츠 담당 | | | |